{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98600640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell 1: Configuration ────────────────────────────────────────────\n",
    "COURSE_FILE       = \"data_course_for_RSv2.xlsx\"\n",
    "JOBS_FILE         = \"combined_all_jobs_requirements.xlsx\"\n",
    "SHEET_NAME        = \"Sheet1\"\n",
    "\n",
    "# ─── Learner Profile ─────────────────────────────────────────────────\n",
    "# DESIRED_JOB       = \"นิติกร\"\n",
    "COURSES_COMPLETED = [\n",
    "    # add more course names here exactly as in your NAME_T column\n",
    "]\n",
    "\n",
    "# ─── Embedding Params & Stopwords ────────────────────────────────────\n",
    "CHUNK_SIZE        = 64\n",
    "thai_stopwords    = {\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75918d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ninen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ─── Imports & Helper Functions ─────────────────────────────────\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(str(text))\n",
    "    return [w for w in tokens if w not in thai_stopwords]\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c678906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Load & Preprocess Data ───────────────────────────────────────\n",
    "courses = pd.read_excel(COURSE_FILE, sheet_name=SHEET_NAME)\n",
    "jobs    = pd.read_excel(JOBS_FILE)\n",
    "jobs    = jobs.rename(columns={\"Job Title\":\"JOB_NAME\", \"Job Description\":\"REQUIREMENTS\"})\n",
    "\n",
    "courses[\"PROCESSED_DESC\"] = courses[\"C_Description\"].apply(preprocess_text)\n",
    "jobs   [\"PROCESSED_REQ\"]  = jobs  [\"REQUIREMENTS\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2588e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── Load Model & Tokenizer ───────────────────────────────────────\n",
    "# device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\n",
    "# model     = AutoModel.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\\\n",
    "#                 .to(device).eval()\n",
    "# vocab_size = model.config.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1efd3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell 5: TF-IDF + SVD embeddings ────────────────────────────────────\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition      import TruncatedSVD\n",
    "from scipy import sparse\n",
    "\n",
    "# 1) Build TEXT_CLEAN columns if you haven’t already\n",
    "jobs   ['TEXT_CLEAN'] = jobs   ['PROCESSED_REQ'].apply(lambda toks: ' '.join(toks))\n",
    "courses['TEXT_CLEAN'] = courses['PROCESSED_DESC'].apply(lambda toks: ' '.join(toks))\n",
    "\n",
    "# 2) Fit TF-IDF on all texts\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "all_texts   = pd.concat([jobs['TEXT_CLEAN'], courses['TEXT_CLEAN']])\n",
    "vectorizer.fit(all_texts)\n",
    "\n",
    "# 3) Transform to sparse matrices\n",
    "jobs_tfidf    = vectorizer.transform(jobs['TEXT_CLEAN'])\n",
    "courses_tfidf = vectorizer.transform(courses['TEXT_CLEAN'])\n",
    "\n",
    "# 4) (Optional) Dimensionality reduction\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "# stack the two matrices so that SVD learns joint components\n",
    "combined = sparse.vstack([jobs_tfidf, courses_tfidf])\n",
    "svd.fit(combined)\n",
    "\n",
    "jobs_embs    = svd.transform(jobs_tfidf)\n",
    "courses_embs = svd.transform(courses_tfidf)\n",
    "\n",
    "# 5) Attach back to your DataFrames\n",
    "jobs   ['EMBEDDING'] = list(jobs_embs)\n",
    "courses['EMBEDDING'] = list(courses_embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e78038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_profile = {\n",
    "    \"desired_job\": \"นักโภชนาการ\",\n",
    "    \"courses_completed\": [\n",
    "        \"จริยธรรมเพื่อการดำเนินชีวิต\",\n",
    "        \"สังคมไทยและโลกาภิวัตน์\",\n",
    "        \"พฤติกรรมสุขภาพ\",\n",
    "        \"การอ่านและการเขียนภาษาอังกฤษทั่วไป\",\n",
    "        \"การบริหารงานสาธารณสุข\",\n",
    "        \"ชีววิทยาเบื้องต้น\",\n",
    "        \"การพัฒนาทักษะการคิด\",\n",
    "        \"การสร้างเสริมสุขภาพ\",\n",
    "        \"การวิจัยทางสาธารณสุข\",\n",
    "        \"สังคมวิทยาและมานุษยวิทยาสาธารณสุข\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6968a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your desired job is:\n",
      "นักโภชนาการ\n",
      "\n",
      "Recommended Courses:\n",
      "                                             C_Name  \\\n",
      "28        วิทยาศาสตร์เพื่อคุณภาพชีวิตและสิ่งแวดล้อม   \n",
      "94                                       สหกิจศึกษา   \n",
      "37            กฎหมายและจริยธรรมในวิชาชีพคอมพิวเตอร์   \n",
      "117                         สัมมนากระบวนการยุติธรรม   \n",
      "54                              โภชนศาสตร์สาธารณสุข   \n",
      "70                              การเตรียมสหกิจศึกษา   \n",
      "141  กฎหมายเกี่ยวกับการกระทำความผิดของเด็กและเยาวชน   \n",
      "115                            หลักวิชาชีพนักกฎหมาย   \n",
      "72                          ปรัชญาและศาสนาเบื้องต้น   \n",
      "142                   การฝึกประสบการณ์วิชาชีพกฎหมาย   \n",
      "\n",
      "                                         C_Description  SIMILARITY  \n",
      "28   กระบวนการและการพัฒนาวิทยาศาสตร์และเทคโนโลยีและ...    0.069876  \n",
      "94   รายวิชาที่ต้องเรียนมาก่อน\\n14074802  การเตรียม...    0.054310  \n",
      "37    ประวัติความเป็นมาของแนวคิดเกี่ยวกับจริยธรรม น...    0.053171  \n",
      "117      กระบวนการยุติธรรมที่เป็นประเด็นในท้องถิ่นแ...    0.049215  \n",
      "54   ความหมายและความสำคัญของโภชนาการต่อสุขภาพ อาหาร...    0.043114  \n",
      "70   การเตรียมสหกิจศึกษาในสถานบริการสาธารณสุขหรือหน...    0.043053  \n",
      "141  ความหมายของเด็กและเยาวชน  สาเหตุแห่งการกระทำผิ...    0.042750  \n",
      "115      วิวัฒนาการของวิชาชีพกฎหมาย  หน้าที่และงานข...    0.041522  \n",
      "72   ประวัติความเป็นมา คุณค่า ความมุ่งหมายสูงสุด พิ...    0.041412  \n",
      "142      ฝึกงานด้านกฎหมายในองค์การภาครัฐ รัฐวิสาหกิ...    0.040647  \n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 6b: Filter out completed courses & recommend ──────────────────\n",
    "desired_job_vector = jobs.loc[jobs[\"JOB_NAME\"] == learner_profile['desired_job'], \"EMBEDDING\"].iloc[0]\n",
    "\n",
    "# 1) Exclude courses the learner has already taken\n",
    "candidates = courses[~courses[\"C_Name\"].isin(learner_profile['courses_completed'])].copy()\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "candidates['SIMILARITY'] = candidates[\"EMBEDDING\"].apply(\n",
    "    lambda x: cosine_similarity([desired_job_vector], [x])[0][0])\n",
    "\n",
    "# Top course recommendations\n",
    "candidates_unique = candidates.drop_duplicates(subset=\"C_Name\", keep=\"first\")\n",
    "candidates_sorted = candidates_unique.sort_values(['SIMILARITY'], ascending=False).head(10)\n",
    "# 2\n",
    "# 3\n",
    "# 4\n",
    "# 8\n",
    "# 15\n",
    "# 51\n",
    "# 60\n",
    "# 65\n",
    "# 67\n",
    "# 94\n",
    "\n",
    "\n",
    "# Output recommendations\n",
    "print(\"Your desired job is:\")\n",
    "print(learner_profile['desired_job'])\n",
    "print(\"\\nRecommended Courses:\")\n",
    "print(candidates_sorted[[\"C_Name\", \"C_Description\", \"SIMILARITY\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
