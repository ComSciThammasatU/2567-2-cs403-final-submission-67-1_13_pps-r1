{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98600640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell 1: Configuration ────────────────────────────────────────────\n",
    "COURSE_FILE       = \"data_course_for_RSv2.xlsx\"\n",
    "JOBS_FILE         = \"combined_all_jobs_requirements.xlsx\"\n",
    "SHEET_NAME        = \"Sheet1\"\n",
    "\n",
    "# ─── Learner Profile ─────────────────────────────────────────────────\n",
    "DESIRED_JOB       = \"\"\n",
    "COURSES_COMPLETED = [ \n",
    "]\n",
    "# ─── Embedding Params & Stopwords ────────────────────────────────────\n",
    "# CHUNK_SIZE        = 256\n",
    "thai_stopwords    = {\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75918d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ninen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ─── Imports & Helper Functions ─────────────────────────────────\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(str(text))\n",
    "    return [w for w in tokens if w not in thai_stopwords]\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c678906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Load & Preprocess Data ───────────────────────────────────────\n",
    "courses = pd.read_excel(COURSE_FILE, sheet_name=SHEET_NAME)\n",
    "jobs    = pd.read_excel(JOBS_FILE)\n",
    "jobs    = jobs.rename(columns={\"Job Title\":\"JOB_NAME\", \"Job Description\":\"REQUIREMENTS\"})\n",
    "\n",
    "courses[\"PROCESSED_DESC\"] = courses[\"C_Description\"].apply(preprocess_text)\n",
    "jobs   [\"PROCESSED_REQ\"]  = jobs  [\"REQUIREMENTS\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2588e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ninen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 4: Load SBERT Model ───────────────────────────────────────\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# pick your SBERT model\n",
    "MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load SentenceTransformer\n",
    "sbert_model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "\n",
    "# enforce the 512-token max\n",
    "sbert_model.tokenizer.model_max_length = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1efd3bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:01<00:00,  1.72it/s]\n",
      "Batches: 100%|██████████| 5/5 [00:02<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 5: Batch-encode with SBERT ─────────────────────────────────\n",
    "# prepare clean text\n",
    "jobs   ['TEXT_CLEAN']   = jobs   ['PROCESSED_REQ'].apply(lambda toks: ' '.join(toks))\n",
    "courses['TEXT_CLEAN']   = courses['PROCESSED_DESC'].apply(lambda toks: ' '.join(toks))\n",
    "\n",
    "# encode in one go\n",
    "jobs_embs    = sbert_model.encode(\n",
    "    jobs['TEXT_CLEAN'].tolist(),\n",
    "    batch_size=32,\n",
    "    convert_to_numpy=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "courses_embs = sbert_model.encode(\n",
    "    courses['TEXT_CLEAN'].tolist(),\n",
    "    batch_size=32,\n",
    "    convert_to_numpy=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# attach embeddings\n",
    "jobs   ['EMBEDDING']   = list(jobs_embs)\n",
    "courses['EMBEDDING']   = list(courses_embs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7053b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell 6a (after you’ve computed EMBEDDING columns) ─────────────────\n",
    "from sklearn.preprocessing import normalize as sk_normalize\n",
    "\n",
    "# stack into a 2D array, normalize row-wise, then unpack back to lists\n",
    "jobs_embs = np.stack(jobs[\"EMBEDDING\"].to_list())          # shape (n_jobs, dim)\n",
    "courses_embs = np.stack(courses[\"EMBEDDING\"].to_list())    # shape (n_courses, dim)\n",
    "\n",
    "jobs_embs    = sk_normalize(jobs_embs,    axis=1)          # each row → unit length\n",
    "courses_embs = sk_normalize(courses_embs, axis=1)\n",
    "\n",
    "jobs[\"EMBEDDING\"]    = list(jobs_embs)                     # back into DataFrame\n",
    "courses[\"EMBEDDING\"] = list(courses_embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13a65480",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_profile = {\n",
    "    \"desired_job\": \"นักโภชนาการ\", \n",
    "    \"courses_completed\": [\n",
    "        \"จริยธรรมเพื่อการดำเนินชีวิต\",\n",
    "        \"สังคมไทยและโลกาภิวัตน์\",\n",
    "        \"พฤติกรรมสุขภาพ\",\n",
    "        \"การอ่านและการเขียนภาษาอังกฤษทั่วไป\",\n",
    "        \"การบริหารงานสาธารณสุข\",\n",
    "        \"ชีววิทยาเบื้องต้น\",\n",
    "        \"การพัฒนาทักษะการคิด\",\n",
    "        \"การสร้างเสริมสุขภาพ\",\n",
    "        \"การวิจัยทางสาธารณสุข\",\n",
    "        \"สังคมวิทยาและมานุษยวิทยาสาธารณสุข\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9844455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your desired job is:\n",
      "นักโภชนาการ\n",
      "\n",
      "Recommended Courses:\n",
      "                                         C_Name  \\\n",
      "54                          โภชนศาสตร์สาธารณสุข   \n",
      "23                   เทคโนโลยีการเพาะเลี้ยงกุ้ง   \n",
      "83   การวางแผนและการประเมินโครงการด้านสาธารณสุข   \n",
      "67                       ปัญหาพิเศษทางสาธารณสุข   \n",
      "126                  กฎหมายเกี่ยวกับสิ่งแวดล้อม   \n",
      "84                         ชีวสถิติทางสาธารณสุข   \n",
      "87                            อนามัยสิ่งแวดล้อม   \n",
      "56                    อาชีวอนามัยและความปลอดภัย   \n",
      "53                  สุขศึกษาและการสื่อสารสุขภาพ   \n",
      "20                      ระบบสนับสนุนการตัดสินใจ   \n",
      "\n",
      "                                         C_Description  SIMILARITY  \n",
      "54   ความหมายและความสำคัญของโภชนาการต่อสุขภาพ อาหาร...    0.586454  \n",
      "23   การจัดจำแนกชีววิทยาและนิเวศวิทยาของกุ้ง  การใช...    0.512087  \n",
      "83   การวางแผน รูปแบบ หลักการในการวางแผน การเขียนโค...    0.492988  \n",
      "67   การศึกษาปัญหาด้านสาธารณสุขโดยใช้กระบวนการวิจัย...    0.476227  \n",
      "126       แนวความคิด   วิธีการต่างๆ กฎหมายและกฎข้อบ...    0.475612  \n",
      "84    หลักการเบื้องต้น ความหมาย ขอบเขต ประโยชน์ของส...    0.466394  \n",
      "87   ความหมาย ความสำคัญของงานอนามัยสิ่งแวดล้อม ขอบเ...    0.456975  \n",
      "56   ความหมายและความสำคัญของงานอาชีวอนามัย ระบาดวิท...    0.449563  \n",
      "53   ความหมาย ความสำคัญ แนวคิด ขอบเขตของสุขศึกษา กล...    0.435155  \n",
      "20   ศึกษารูปแบบ ประเภท เทคนิคการทำเหมืองข้อมูล การ...    0.423914  \n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 6b: Filter, dedupe & recommend ───────────────────────────────\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1) Exclude courses the learner has already taken\n",
    "candidates = courses[~courses[\"C_Name\"].isin(learner_profile['courses_completed'])].copy()\n",
    "\n",
    "# 2) Compute similarity to the desired-job vector\n",
    "desired_vec = jobs.loc[jobs[\"JOB_NAME\"] == (learner_profile['desired_job']), \"EMBEDDING\"].iloc[0]\n",
    "candidates[\"SIMILARITY\"] = candidates[\"EMBEDDING\"].apply(\n",
    "    lambda v: cosine_similarity([desired_vec], [v])[0][0]\n",
    ")\n",
    "\n",
    "candidates_unique = candidates.drop_duplicates(subset=\"C_Name\", keep=\"first\")\n",
    "candidates_unique = candidates_unique.sort_values(['SIMILARITY'], ascending=False).head(10)\n",
    "\n",
    "print(\"Your desired job is:\")\n",
    "print(learner_profile['desired_job'])\n",
    "\n",
    "print(\"\\nRecommended Courses:\")\n",
    "print(candidates_unique[[\"C_Name\", \"C_Description\", \"SIMILARITY\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
